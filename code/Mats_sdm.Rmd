---
title: "Mat_sdm"
author: "Khum"
date: "2022-10-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
dir.create("../code")
dir.create("../data")
dir.create("../data_output")
```


## Making the list of files withing the data folder


```{r}
# loading libraries
library(raster)
library(dplyr)
library(rgdal)
library(sf)
library(ggplot2)

```

## listing the files that are strictly .tif files
```{r}
list.files("C:/Users/Khum/OneDrive - UCB-O365/MBM_sdm_data/mat_rasters", pattern=".tif$")
```

#making path for each .tif files
```{r}
path<-"C:/Users/Khum/OneDrive - UCB-O365/MBM_sdm_data/mat_rasters"

path_albedo <-paste0(path,"/WV02_20181211_210021_1030010089D13500_ALBEDO.tif")
path_blkmat<-paste0(path,"/WV02_20181211_210021_1030010089D13500_BLKMAT.tif")
path_grnte<-paste0(path,"/WV02_20181211_210021_1030010089D13500_GRNTE.tif")
path_moss<-paste0(path,"/WV02_20181211_210021_1030010089D13500_MOSS.tif")
path_orgmat<-paste0(path,"/WV02_20181211_210021_1030010089D13500_ORGMAT.tif")
path_soil<-paste0(path,"/WV02_20181211_210021_1030010089D13500_SOIL.tif")
path_vwc<-paste0(path,"/WV02_20181211_210021_1030010089D13500_VWC.tif")
path_water<-paste0(path,"/WV02_20181211_210021_1030010089D13500_WATER.tif")
path_snow_ice<-paste0(path,"/WV02_20181211210021_1030010089D13500_18DEC11210021-M1BS-502958123080_01_P001_f32ns3031_rad_refl_CalTargets_Snow_Ice.tif")
path_vwc_setzero<-paste0(path,"/WV02_20181211210021_1030010089D13500_hs_NormalizedAlbedo_ratio_VWC_SetZero.tif")

# reading as raster file to all the paths

albedo<-raster(path_albedo)
blkmat<-raster(path_blkmat)
grnte<-raster(path_grnte)
moss<-raster(path_moss)
orgmat<-raster(path_orgmat)
soil<-raster(path_soil)
vwc<-raster(path_vwc) # it has different extent to env
water<-raster(path_water)
snow_ice<-raster(path_snow_ice)
vwc_setzero<-raster(path_vwc_setzero)

```

## reproject soil and water  to vwc which has coarser resolution
## it is easy to from finer scale to coarser scale

```{r}


## first reduce the size to AOI (these two file has large area cover)

ty_snow<- read_sf("C:/Users/Khum/OneDrive - UCB-O365/MBM_sdm_data/TaylorValley_shape/Polygons.shp")%>%
  st_transform(crs(snow_ice))

ty_vwc_setzero<- read_sf("C:/Users/Khum/OneDrive - UCB-O365/MBM_sdm_data/TaylorValley_shape/Polygons.shp")%>%
  st_transform(crs(vwc_setzero))

snow_snow_crop<-crop(snow_ice,ty_snow)
vwc_setzero_crop<-crop(vwc_setzero,ty_vwc_setzero)

ty_soil<- read_sf("C:/Users/Khum/OneDrive - UCB-O365/MBM_sdm_data/TaylorValley_shape/Polygons.shp")%>%
  st_transform(crs(soil))

ty_water<- read_sf("C:/Users/Khum/OneDrive - UCB-O365/MBM_sdm_data/TaylorValley_shape/Polygons.shp")%>%
  st_transform(crs(water))

ty_vwc<- read_sf("C:/Users/Khum/OneDrive - UCB-O365/MBM_sdm_data/TaylorValley_shape/Polygons.shp")%>%
  st_transform(crs(vwc))

soil_crop<-crop(soil,ty_soil)
water_crop<-crop(water,ty_water)
vwc_crop<-crop(vwc,ty_vwc)


```


```{r}
## reproject snow_ice and vwc to the soil
# vwc_crop as source of extent and resolustions

soil_proj<-projectRaster(soil,crs=crs(vwc))
water_proj<-projectRaster(water_crop,crs=crs(vwc_crop))

snow_ice_proj<-projectRaster(snow_snow_aoi,crs=crs(vwc_crop))
vwc_setzero_proj<-projectRaster(vwc_setzero_aoi,crs=crs(vwc_crop))

g<-raster::stack(vwc_crop,snow_ice_proj)# working goods

plot(vwc)
plot(ty$geometry,add=T)

```

## masked file

```{r}

list_mat<-list.files("C:/Users/Khum/Documents/mbm_output/mat_masked",pattern=".tif$", full.names=TRUE)

env<-raster::stack(list_mat)
```




## crop in the same size by AOI

```{r}


```


## stack predictor varibles of soil, vwc,snow_ice

```{r}
env<-raster::stack(soil_crop,water_crop,vwc_proj_crop)

v<-raster::stack(vwc_setzero,snow_ice)
```


## reading the AOI polygons

```{r}
# read polygons and transform based on orange mats

ty<- read_sf("C:/Users/Khum/OneDrive - UCB-O365/MBM_sdm_data/TaylorValley_shape/Polygons.shp")%>%
  st_transform(crs(orgmat))

## chekcing if the AOI overalps witht he raster layers selected
plot(orgmat)
plot(ty,add=T)

```


```{r}
# getting example file making similar projections
# r<- getData('alt',country="IND",mask=TRUE,path="../data/Try_data")

# sources for converting similar projections

alt<-raster("C:/Users/Khum/OneDrive - UCB-O365/MBM_sdm_data/ex_rs_projection/IND_msk_alt.gri")

## reprojecting orgmat 
orgmat_pr<-projectRaster(orgmat,crs=crs(alt))

ty<- read_sf("C:/Users/Khum/OneDrive - UCB-O365/MBM_sdm_data/TaylorValley_shape/Polygons.shp")%>%
  st_transform(crs(orgmat_pr))

## chekcing if the AOI overalps witht he raster layers selected
plot(orgmat)
plot(ty,add=T)

# lets crop the orane mat using AOI

orgmat_crop<-crop(orgmat_pr,ty)

## getting abundance values that is greater than 50

orgmat_crop_50<-orgmat_crop>0.50

# looking the number of pixels in the layer
cellStats(orgmat_crop_50,'sum')

orgmat.df<-as.data.frame(orgmat_crop_50,xy=TRUE)%>%
  filter(layer=="TRUE")%>%
  as.data.frame()

# smaple randomly 1000 points out of total 34289
orgmat.df<-orgmat.df[sample(nrow(orgmat.df), size=1000),]

# double check if the 1000 random sampels are selected
plot(orgmat_crop, main="1000 points")
points(orgmat.df$x,orgmat.df$y, add=T)


## Thining the GPS points by 1km way

library(spThin)

thin_path<-("../data_output/mat_rarified")

# lets use thin function for the rarifaction of the presence points

thin(orgmat.df, lat.col="y", long.col="x", spec.col="layer", thin.par=1, reps=1, out.dir=thin_path, out.base="orgmat")

# read the thin csv file to double check and make ready for the analysis
orgmat_thin<-read.csv("../data_output/mat_rarified/orgmat_thin1.csv")%>%
  rename(long=x,lat=y)%>%
  select(-1)%>%
  mutate(pres=rep(1,16))# paste0 concatenate the two words

# test if thin coordinates overlap in the layer
plot(orgmat_crop_50, main="Thined by 1km")
points(orgmat_thin$long,orgmat_thin$lat, add=T)

```


# working in the independent variables
```{r}
# now covert NA values into zero
#NAvalue(soil)<--9999

elevation<-raster("C:/Users/Khum/OneDrive - UCB-O365/MBM_sdm_data/Shen_DEM/Antarctic DEM from ICESat-2.tif")
# getting slope and aspect 
slope<-terrain(elevation,opt=c("slope"), unit="radians")
aspect<-terrain(elevation,opt=c("aspect"),unit="radians")

## head load index if needed in the analysis

library(raster)
library(spatialEco)
#data(elev)
heat_load <- hli(elevation)

#plot(heat_load, main="Heat Load Index")

env<-stack(elevation,aspect)

# env <- stack(soil,water)

ty_tr<- read_sf("C:/Users/Khum/OneDrive - UCB-O365/Research_analaysis_R/data/TaylorValley_shape/Polygons.shp")%>%
  st_transform(crs(env))

# cropping the environmental variables
env_crop<-crop(env,ty_tr)

#convert env_crop as alt projection
elevation_crop<-projectRaster(env_crop$Antarctic_DEM_from_ICESat.2,crs=crs(alt))
aspect_crop<-projectRaster(env_crop$aspect,crs=crs(alt))

env_crop1<-stack(elevation_crop,aspect_crop)

plot(env_crop1$Antarctic_DEM_from_ICESat.2)
points(orgmat_thin$long,orgmat_thin$lat, add=T)


```

# note the results will be in the code folder
# will find how to chang it
```{r}
library(biomod2)
# lets set up the models

# explanatory variables need to without NA
## format the data ----

mat_data <- 
  BIOMOD_FormatingData(
    resp.var = orgmat_thin['pres'],
    resp.xy = orgmat_thin[, c('long', 'lat')],
    expl.var = env_crop1,
    resp.name = "OrangeMat",
    PA.nb.rep = 1,
    PA.nb.absences = 10,
    PA.strategy = 'random'
  )

## define individual models options ---- 

mat_opt <- 
  BIOMOD_ModelingOptions( 
    GLM = list(type = 'quadratic', interaction.level = 1),
    GBM = list(n.trees = 1000),
    GAM = list(algo = 'GAM_mgcv')
  )

## run the individual models ----
mat_models <- 
  BIOMOD_Modeling(
    data = mat_data,
    models = c("GLM", "GBM", "RF", "GAM"),
    models.options = mat_opt,
    NbRunEval = 2,
    DataSplit = 80,
    VarImport = 3,
    modeling.id = "../data_output/orgmat"
  )

## get models evaluation scores
mat_models_scores <- get_evaluations(mat_models)
dim(mat_models_scores)
dimnames(mat_models_scores)
##
(eval.df <- t(data.frame(RUN_1 = mat_models_scores[ , 1, , 1, ],
                         RUN_2 = mat_models_scores[ , 1, , 2, ],
                         RUN_3 = mat_models_scores[ , 1, , 3, ])))


models_scores_graph(mat_models,by="models",metrics=c("ROC","TSS"))

## evaluations
(mat_models_var_import <- get_variables_importance(mat_models))

## run the ensemble models ----
mat_ensemble_models <- 
  BIOMOD_EnsembleModeling(
    modeling.output = mat_models,
    em.by = 'all',
    eval.metric = 'TSS',
    eval.metric.quality.threshold = 0.2,
    models.eval.meth = c('TSS','ROC'),
    prob.mean = FALSE,
    prob.cv = TRUE, 
    committee.averaging = TRUE,
    prob.mean.weight = TRUE,
    VarImport = 0
  )

## asses ensemble models quality ----
(mat_ensemble_models_scores <- get_evaluations(mat_ensemble_models))

## current projections
mat_models_proj_current <- 
  BIOMOD_Projection(
    modeling.output = mat_models,
    new.env = env_crop1,
    proj.name = "current",
    binary.meth = "TSS",
    output.format = ".img",
    do.stack = FALSE
  )

myCurrentProj<-get_predictions(mat_models_proj_current)
plot(myCurrentProj)

mat_ensemble_models_proj_current <- 
  BIOMOD_EnsembleForecasting(
    EM.output = mat_ensemble_models,
    projection.output = mat_models_proj_current,
    binary.meth = "TSS",
    output.format = ".img",
    do.stack = FALSE
  )

```

## predicted maps

```{r}
org_p<-raster("C:/Users/Khum/OneDrive - UCB-O365/MBM_sdm/code/OrangeMat/proj_current/individual_projections/OrangeMat_EMcaByTSS_mergedAlgo_mergedRun_mergedData.img")

plot(org_p/1000)
plot(ty, add=T,color="red")

```


